# -*- coding: utf-8 -*-

"""## the Author Email  **karimeldeeb2001@gmail.com**
## the Author what's up number  **+201555604511**
"""

"""how_to_train_Segmentation_model_on_cancer_tumor_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/KKAARRIIMM15/Cancer-Tumor-instance-segmentation-/blob/main/how_to_train_Segmentation_model_on_cancer_tumor_dataset.ipynb
"""


from google.colab import drive
drive.mount('/content/drive')
import os.path
path = 'drive//MyDrive//Tumor//config2.yaml'
check_file = os.path.isfile(path)

print(check_file)

def plot_orginal_and_detection( orginal_im , im ):

  orginal_im = cv2.cvtColor(orginal_im, cv2.COLOR_BGR2RGB)

  fig, axs = plt.subplots(1, 2, figsize=(12, 8))  # 1 row, 2 columns

  # Display the original image on the left
  axs[0].imshow(orginal_im)
  axs[0].set_title('Original Image')
  axs[0].axis('off')  # Hide the axes

  # Display the detection result on the right
  axs[1].imshow(im)
  axs[1].set_title('Detection')
  axs[1].axis('off')  # Hide the axes

  plt.subplots_adjust(wspace=1.0)

  # Show the plot
  plt.tight_layout()
  plt.show()

"""### **this funcation shows how the extract segment of each tumor then perform canny edge detection then find the external contours of the tumor edge**"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def extract_all_segments( new_result ):
  if new_result.masks == None:
    print(" \n No Cancer tumor\n")

  extracted_masks = new_result.masks.data
  detected_boxes = new_result.boxes.data

  i = 0;  conf = [ ];  x1 = [ ];    y1 = [ ]
  while(i < len(detected_boxes) ):
    conf.append(detected_boxes[i][4]);   x1.append(detected_boxes[i][0]);     y1.append(detected_boxes[i][1])
    i=i+1

  class_labels = detected_boxes[:, -1].int().tolist()
  masks_by_class = {name: [] for name in new_result.names.values()}


  for mask, class_id , confdnce in zip(extracted_masks, class_labels, conf):
    if( confdnce > 0.1):
      class_name = new_result.names[class_id]
      masks_by_class[class_name].append(mask.numpy())

  for class_name, masks in masks_by_class.items():
    print(f"Class Name: {class_name}, Number of Masks: {len(masks)}")

  tumorMask = masks_by_class['tumor']
  tumorMask = np.array(tumorMask)

  i = 0
  while(i < len(tumorMask) ):
    TMask = tumorMask[i]
    TMask = TMask.reshape(TMask.shape[0], TMask.shape[1])

    TMask = TMask * 255
    TMask = cv2.resize(TMask, (W, H))
    TMask = TMask.astype(np.uint8)

    edges = cv2.Canny(TMask, 50, 100)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(image, contours, -1, (0, 205, 0), 2)

    '''target_pixel = [0, 0, 0]
    pixel_count = np.sum(np.all(image == target_pixel, axis=-1))
    area = cv2.contourArea(contours[0])
    area = (area / ( (W * H)-pixel_count ) ) * 100;   area = "{:.2f}".format(area);'''

    cv2.putText(image, str(i+1), (int(x1[i] + 20), int(y1[i] - 2)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (20, 230, 20), 1, cv2.LINE_AA)
    i = i + 1

  return image



class Segment:
    def __init__(self, msk, scr, lbl , box):
        self.MASK = msk;    self.SCORE = scr;   self.label = lbl;  self.BOX = box


def calculate_overlap(mask1, mask2):
    # Calculate the intersection and union between two masks
    intersection = np.logical_and(mask1, mask2)
    union = np.logical_or(mask1, mask2)

    # Calculate percentage of overlap as IoU
    if np.sum(union) == 0:
        return 0
    return (np.sum(intersection) / np.sum(union)) * 100


def get_overlapping_segments(segments, threshold=20):
    overlapping_segments = []

    # Check for overlap between all pairs of segments
    for i in range(len(segments)):
        for j in range(i + 1, len(segments)):
            overlap_percentage = calculate_overlap(segments[i].MASK, segments[j].MASK)
            if overlap_percentage > threshold:
                # Add segments that have sufficient overlap to the result list
                overlapping_segments.append(segments[i])
                overlapping_segments.append(segments[j])

    # Remove duplicates from the list of overlapping segments
    overlapping_segments = list(set(overlapping_segments))

    return overlapping_segments


def get_highest_score_segment(segments):
    # Ensure there are segments to compare
    if not segments:
        return None, None, None, None

    # Find the segment with the highest score
    best_segment = max(segments, key=lambda seg: seg.SCORE)

    return best_segment.MASK, best_segment.SCORE, best_segment.label, best_segment.BOX



"""## **Start Training**

**this path ---> "drive//MyDrive//Tumor//config2.yaml"   contain the training data for each image and its label**
"""

from ultralytics import YOLO
model = YOLO("yolov8n-seg.yaml")
results = model.train(model="yolov8n-seg.yaml", data="drive//MyDrive//Tumor//config2.yaml", imgsz=1024 ,
                      optimizer="SGD" , epochs=40 ,batch=5, lr0=0.008 , lrf=0.1)

/content/runs/segment/train/weights/last.pt

"""### **Prediction Phase**"""

from ultralytics import YOLO

model = YOLO("drive//MyDrive//Tumor//cancer_tumor.pt")
image = cv2.imread( "drive//MyDrive//Tumor//dataset//images//train//Tr-me_0323.jpg" )
H, W, _ = image.shape

new_result = model.predict(image)[0]
img = extract_all_segments( new_result )

image = cv2.imread( "drive//MyDrive//Tumor//dataset//images//train//Tr-me_0323.jpg" )
plot_orginal_and_detection( image , img )

image = cv2.imread( "drive//MyDrive//Tumor//dataset//images//train//Tr-me_0040.jpg" )
H, W, _ = image.shape

new_result = model.predict(image)[0]
img = extract_all_segments( new_result )

image = cv2.imread( "drive//MyDrive//Tumor//dataset//images//train//Tr-me_0040.jpg" )
plot_orginal_and_detection( image , img )

image = cv2.imread( "drive//MyDrive//Tumor//dataset//images//train//Tr-gl_0586.jpg" )
H, W, _ = image.shape

new_result = model.predict(image)[0]
img = extract_all_segments( new_result )

image = cv2.imread( "drive//MyDrive//Tumor//dataset//images//train//Tr-gl_0586.jpg" )
plot_orginal_and_detection( image , img )





"""### **Why YOLO algorithm for Brain Tumor Detection?**

**1- Fast object detection:** YOLO is designed for real-time object detection. This makes it highly efficient in identifying brain tumors in the very low hardware resources machines, which is crucial in medical applications where time is important with limmited resources computers unlike the two stage algorthims as the familly of R-CNN that has high number of parameters which make it heavy algorithms.


**2- Localization:** YOLO's streamlined architecture allows it to detect tumors with high precision, even when they vary in size, shape, light condition or location within the brain, making it a reliable tool for medical imaging tasks.
"""
